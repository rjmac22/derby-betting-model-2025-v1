{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f626201a-12ed-4f52-8217-c59053171960",
   "metadata": {},
   "source": [
    "# 🧱 02 – Data Preparation & Cleaning\n",
    "\n",
    "This notebook creates a clean, structured version of the 2019 flat racing dataset for modelling.\n",
    "\n",
    "We apply:\n",
    "- Safe renames and value corrections identified in the previous data integrity audit\n",
    "- Minor derived columns (e.g. did_finish)\n",
    "- Optional filters for clean modelling subsets\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Why This Step Matters\n",
    "\n",
    "Rather than modifying raw data in-place, we follow **best practice** in data workflows:\n",
    "\n",
    "- 📦 **Raw files remain untouched**, ensuring a reliable reference point and audit trail\n",
    "- 🧪 **All fixes are applied in memory** to a copied DataFrame\n",
    "- 💾 **Processed data is saved separately**, ready for use in modelling notebooks\n",
    "\n",
    "This makes our pipeline:\n",
    "- Reproducible\n",
    "- Traceable\n",
    "- Safe for collaboration and experimentation\n",
    "\n",
    "---\n",
    "By the end of this notebook, we’ll have:\n",
    "- `horses_2019_clean.csv` – cleaned, horse-level data (one row per runner)\n",
    "- `races_2019_clean.csv` – cleaned, race-level metadata (one row per race)\n",
    "\n",
    "We’ll only merge them later if a model or analysis step requires both levels.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ce0fe06-14ad-4a13-934c-a7fe99c06422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Raw data loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set file paths\n",
    "YEAR = 2019\n",
    "horses_path = f\"data/raw/horses_{YEAR}.csv\"\n",
    "races_path = f\"data/raw/races_{YEAR}.csv\"\n",
    "\n",
    "# Load\n",
    "horses = pd.read_csv(horses_path)\n",
    "races = pd.read_csv(races_path)\n",
    "\n",
    "print(\"✅ Raw data loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ddcfd-6160-4f66-9979-6b45460cdb8e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📊 Pre-Cleaning Audit Snapshot\n",
    "\n",
    "Before making any changes, we take a quick look at key columns to establish a baseline.\n",
    "\n",
    "This lets us confirm that:\n",
    "- Our fixes behave as expected\n",
    "- No columns are accidentally dropped, renamed, or altered\n",
    "\n",
    "We'll use this to validate each transformation in the steps ahead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c3faf7b-ae72-46db-abf0-6a93a13e24a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔢 Columns in horses_raw: ['rid', 'horseName', 'age', 'saddle', 'decimalPrice', 'isFav', 'trainerName', 'jockeyName', 'position', 'positionL', 'dist', 'weightSt', 'weightLb', 'overWeight', 'outHandicap', 'headGear', 'RPR', 'TR', 'OR', 'father', 'mother', 'gfather', 'runners', 'margin', 'weight', 'res_win', 'res_place']\n",
      "🔍 Sample values:\n",
      "        decimalPrice  position\n",
      "160292      0.019608        11\n",
      "85252       0.010000        14\n",
      "122870      0.114943         1\n",
      "118465      0.066667         1\n",
      "151957      0.045455         4\n",
      "⚠️ Horses with position == 40 (non-finishers placeholder): 8033\n",
      "🎲 'decimalPrice' stats:\n",
      "count    171849.000000\n",
      "mean          0.120026\n",
      "std           0.118543\n",
      "min           0.001767\n",
      "25%           0.038462\n",
      "50%           0.083333\n",
      "75%           0.163934\n",
      "max           0.961538\n",
      "Name: decimalPrice, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Preview raw structure\n",
    "print(\"🔢 Columns in horses_raw:\", horses.columns.tolist())\n",
    "print(\"🔍 Sample values:\")\n",
    "print(horses[['decimalPrice', 'position']].sample(5))\n",
    "\n",
    "# Optional: count key placeholder values\n",
    "print(\"⚠️ Horses with position == 40 (non-finishers placeholder):\", (horses['position'] == 40).sum())\n",
    "print(\"🎲 'decimalPrice' stats:\")\n",
    "print(horses['decimalPrice'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43d1779-8c9d-4b00-a416-56e35ac36b4a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ Pre-Cleaning Audit Complete\n",
    "\n",
    "The raw data structure and key placeholder values were as expected.\n",
    "\n",
    "- `decimalPrice` contains valid implied probabilities (0 < p < 1)\n",
    "- `position == 40` appears 8,033 times and needs replacing\n",
    "- Column structure matches the dataset documentation\n",
    "\n",
    "We now begin applying our processing steps, one at a time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c524da1-5731-4180-a9df-bb14110346b1",
   "metadata": {},
   "source": [
    "### ✅ Fix 1 – Rename `decimalPrice` to `implied_prob`\n",
    "\n",
    "In our audit, we confirmed that the `decimalPrice` column actually contains **implied win probabilities**, not raw decimal odds.\n",
    "\n",
    "To prevent confusion and make its purpose clearer in downstream modelling, we rename the column to `implied_prob`.\n",
    "\n",
    "This makes the data easier to work with and aligns with probability-based feature naming conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d138f90-f578-43d8-989d-5e2e6852caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename mislabelled column\n",
    "if 'decimalPrice' in horses.columns:\n",
    "    horses = horses.rename(columns={'decimalPrice': 'implied_prob'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1c2e03-02e1-42f5-9dd2-77a863f3753f",
   "metadata": {},
   "source": [
    "✅ **Check: Confirm column rename worked**\n",
    "\n",
    "We do a quick check to confirm that:\n",
    "- The new `implied_prob` column exists\n",
    "- It has numeric values in the expected range (0–1)\n",
    "- The old `decimalPrice` column is no longer present\n",
    "\n",
    "This helps ensure the rename was applied correctly before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f8ae089-b304-47e7-b72e-7f365fa6162d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    171849.000000\n",
       "mean          0.120026\n",
       "std           0.118543\n",
       "min           0.001767\n",
       "25%           0.038462\n",
       "Name: implied_prob, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"implied_prob\" in horses.columns)  # Should be True\n",
    "horses['implied_prob'].describe().head()  # Sanity-check stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5ec88a-ea6b-41c4-870b-7f2f81bf95a0",
   "metadata": {},
   "source": [
    "### ✅ Fix 2 – Replace `position == 40` with `NaN`\n",
    "\n",
    "In our audit, we saw that 8,033 entries in the `position` column had the value `40`.\n",
    "\n",
    "This value acts as a placeholder for non-finishers and should not be treated as a true finishing place.\n",
    "\n",
    "To avoid misleading our model, we replace these values with `NaN`.\n",
    "\n",
    "We'll confirm the fix by:\n",
    "\n",
    "- Checking that there are now **0 entries** with `position == 40`\n",
    "- Verifying that the number of `NaN` values in `position` has increased accordingly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b50b632-859e-418e-afe9-f001b2a7284a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ position == 40: 0\n",
      "✅ Total NaN in position: 8033\n"
     ]
    }
   ],
   "source": [
    "# Replace position == 40 with NaN to flag non-finishers\n",
    "horses['position'] = horses['position'].replace(40, np.nan)\n",
    "\n",
    "# Confirm no '40' values remain\n",
    "print(\"✅ position == 40:\", (horses['position'] == 40).sum())\n",
    "\n",
    "# Confirm total NaNs (should now include the 8033 converted)\n",
    "print(\"✅ Total NaN in position:\", horses['position'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0b1aa5-9de5-4900-967c-f7842ceb1f31",
   "metadata": {},
   "source": [
    "✅ **Result: Placeholder removal successful**\n",
    "\n",
    "- All `position == 40` values have been correctly replaced with `NaN`\n",
    "- `NaN` now signals a non-finisher, without corrupting the numerical integrity of the `position` column\n",
    "- This prepares the data for a clean finish flag and simplifies future modelling logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05889f85-f851-4f2b-9fe8-df93c7ce5ca2",
   "metadata": {},
   "source": [
    "### ✅ Fix 3 – Add `did_finish` Flag\n",
    "\n",
    "The `position` column tells us where a horse finished — but only if they actually completed the race.\n",
    "\n",
    "If a horse failed to finish (e.g. pulled up, unseated, refused), the `position` value is missing (`NaN`).\n",
    "\n",
    "To make this clearer and easier to work with, we create a new binary column: `did_finish`.\n",
    "\n",
    "- `1` means the horse finished the race\n",
    "- `0` means the horse did not finish\n",
    "\n",
    "This flag improves clarity, simplifies filtering, and allows us to explore finish reliability as a potential feature later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cb79ca9-c75b-4582-863a-bbe72e127ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did_finish\n",
      "1    163816\n",
      "0      8033\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create binary finish flag\n",
    "horses['did_finish'] = horses['position'].notna().astype(int)\n",
    "\n",
    "# Check value counts of the new column\n",
    "print(horses['did_finish'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a8ba53-28e0-40c2-a763-923f31970874",
   "metadata": {},
   "source": [
    "✅ **Result: `did_finish` flag successfully added**\n",
    "\n",
    "- 163,816 horses marked as finishers (`did_finish == 1`)\n",
    "- 8,033 horses marked as non-finishers (`did_finish == 0`)\n",
    "- This new feature makes it easy to include/exclude non-finishers or even model completion likelihood\n",
    "\n",
    "The core fixes are now complete and the data is ready for optional filtering, enrichment, or merging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a7276e-dcb6-4ab4-bb16-fa39193a22dd",
   "metadata": {},
   "source": [
    "## 💾 Save Cleaned Horse-Level Data\n",
    "\n",
    "We now save the cleaned `horses` dataset to a processed file.\n",
    "\n",
    "- The original raw file remains untouched\n",
    "- No merge is performed here — we maintain table separation\n",
    "- Merging will be done later, only when required for modelling or analysis\n",
    "## 💾 Also Save Untouched Race Data for Consistency\n",
    "\n",
    "Although we haven’t made any changes to the `races` dataset yet, we save a copy into our `processed/` folder.\n",
    "\n",
    "This avoids confusion later and ensures all modelling notebooks refer to data in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cccae2d9-11ea-43ca-942d-eec475e057a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned horse data saved (no merging)\n",
      "✅ Races data saved (untouched)\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned horse-level data\n",
    "horses.to_csv(f\"data/processed/horses_{YEAR}_clean.csv\", index=False)\n",
    "\n",
    "# Save races data as-is for clarity and consistency\n",
    "races.to_csv(f\"data/processed/races_{YEAR}_clean.csv\", index=False)\n",
    "\n",
    "print(\"✅ Cleaned horse data saved (no merging)\")\n",
    "print(\"✅ Races data saved (untouched)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e033e84e-32c5-4ff4-a8b2-027b7e4cf2ec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ Data Preparation Complete\n",
    "\n",
    "This notebook applied all known and verified cleaning steps to the 2019 horse-level data.\n",
    "\n",
    "We have:\n",
    "\n",
    "- 🧼 Renamed mislabelled columns for clarity (`decimalPrice → implied_prob`)\n",
    "- 🛠️ Handled placeholders (`position == 40` → `NaN`)\n",
    "- 📍 Added a clear `did_finish` flag\n",
    "- 💾 Saved a clean version of the dataset for downstream use\n",
    "- 📂 Stored a copy of the untouched race-level data to maintain consistency\n",
    "\n",
    "We now have a reliable, readable, and reproducible dataset ready for:\n",
    "\n",
    "- 🧪 Feature engineering\n",
    "- 🧠 Exploratory analysis\n",
    "- 🏇 Targeted filtering (e.g. Derby-like races)\n",
    "- 🧮 Modelling workflows\n",
    "\n",
    "Next step: EDA or feature prep — depending on your focus.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
